// nn.wppl
//
// Neural net encoders and decoders for use in encoder/decoder
// models (see enc.wppl).  The nn encoders use webppl-nn
// to construct latent states from inputs, and the nn decoders
// decode the latent states into outputs.  There are also
// neural net 'step functions' (e.g. lstm) for use in the sequence
// encoders and decoders from seq.wppl.
//


// Specifies whether deocder has a sigmoid, linear,
// softmax, or constant output later
var NN_DECODER_SIGMOID = 0;
var NN_DECODER_LINEAR = 1;
var NN_DECODER_SOFTMAX = 2;
var NN_DECODER_CONSTANT = 3;

// Specifies whether encoder uses a tanh activation layer,
// or ignores the input and acts as a constant function
var NN_ENCODER_TANH = 0;
var NN_ENCODER_CONSTANT = 1;

// Specifies that a sequence step uses an lstm layer
var NN_SEQUENCE_STEP_LSTM = 0;

// _nn_makeModelParam
//
// Private function for constructing neural network model params
//
// Return model parameter
var _nn_makeModelParam = function(name, maybeDims) {
    guide(function () {
        globalStore['nnParams_' + name] = param({ name : 'nnParams_' + name, dims : maybeDims });
    });
    return globalStore['nnParams_' + name];
}

// _nn_makeState
//
// Private function to construct initial latent state
//
// params:
//   name : Reference name
//   dimension : Dimension of state
//
// return state
var _nn_makeState = function(params) {
    return _nn_makeModelParam("state_" + params.name,  [params.dimension, 1]);
};


// nn_initEncoder
//
// params:
//   name : Reference name
//   encoderType : (NN_ENCODER_TANH, NN_ENCODER_CONSTANT)
//   inputDimension : Dimension of the input
//   latentDimension : Dimension of hidden state
//   [constantFn] : constant encoder function if encoder type is constant (() -> initial state)
//
// return neural net encoder
var nn_initEncoder = function(params) {
    if (params.encoderType === NN_ENCODER_TANH) {
        var encoderFn = stack([
            tanh,
            bias("enc_bias_0_" + params.name, { out : params.latentDimension, param : modelParam }),
            affine('enc_layer_0_' + params.name, { in : params.inputDimension, out : params.latentDimension, param : modelParam })
        ]);

        return _.extend(_.clone(params), { encoderFn : encoderFn });
    } else if (params.encoderType == NN_ENCODER_CONSTANT) {
        if (params.constantFn !== undefined) {
            var constantFn = params.constantFn;
            return _.extend(_.clone(params), { encoderFn : constantFn });
        }
        var initialState = _nn_makeState({ name : params.name, dimension : params.latentDimension });
        var encoderFn = function() { return initialState };
        return _.extend(_.clone(params), { initialState : initialState, encoderFn : encoderFn });
    }
};

// nn_applyEncoder
//
// encoder : encoder initialized by nn_initEncoder
// input : Input to the encoder
//
// return latent state constructed from encoder applied to input
var nn_applyEncoder = function(encoder, input, maybeState) {
    var encoderFn = encoder.encoderFn;
    return encoderFn(input);
}

// nn_initDecoder
//
// params:
//   name : Reference name
//   decoderType : Activation function at output later (NN_DECODER_SIGMOID, NN_DECODER_LINEAR, NN_DECODER_SOFTMAX)
//   latentDimension : Dimension of latent input
//   outputDimension : Dimension of output later
//
// return neural net decoder object
var nn_initDecoder = function(params) {
    if (params.decoderType == NN_DECODER_SIGMOID) {
        var decoderFn = stack([
            sigmoid,
            affine('dec_layer_0_' + params.name, { in : params.latentDimension, out : params.outputDimension, param : modelParam })
        ]);

        return _.extend(_.clone(params), { decoderFn : decoderFn });
    } else if (params.decoderType == NN_DECODER_LINEAR) {
        var decoderFn = stack([
            affine('dec_layer_0_' + params.name, { in : params.latentDimension, out : params.outputDimension, param : modelParam })
        ]);

        return _.extend(_.clone(params), { decoderFn : decoderFn });
    } else if (params.decoderType == NN_DECODER_SOFTMAX) {
        var decoderFn = stack([
            softmax,
            affine('dec_layer_0_' + params.name, { in : params.latentDimension, out : params.outputDimension, param : modelParam })
        ]);

        return _.extend(_.clone(params), { decoderFn : decoderFn });
    } else if (params.decoderType == NN_DECODER_CONSTANT) {
        var constantFn = params.constantFn;
        return _.extend(_.clone(params), { decoderFn : constantFn });
    }
};

// nn_applyDecoder
//
// decoder : decoder initialized by nn_initDecoder
// input : observed input (probably passed through encoder to construct state)
// latentState : state output by an encoder
//
// return output resulting from applying decoder to latent state
var nn_applyDecoder = function(decoder, input, latentState) {
    var decoderFn = decoder.decoderFn;
    return decoderFn(latentState);
};

// nn_decodeDistribution
//
// decoder : decoder initialized by nn_initDecoder
// input : observed input (probably passed through encoder to construct state)
// latentState : State to decode
// distributionFn : decoder output, input, decoder -> Distribution
// [maybeObservation] : Observation to factor on
//
// return distribution object constructed from decoder
var nn_decodeDistribution = function(decoder, input, latentState, distributionFn, maybeObservation) {
    return distributionFn(nn_applyDecoder(decoder, input, latentState), input, decoder, maybeObservation);
};

// nn_decodeLL
//
// decoder : decoder initialized by nn_initDecoder
// output : observed output
// input : observed input (probably passed through encoder to construct state)
// latentState : State to decode
// distributionFn : decoder output, input, decoder -> Distribution
//
// return log likelihood score of given output
var nn_decodeLL = function(decoder, output, input, latentState, distributionFn) {
    var Dist = distributionFn(nn_applyDecoder(decoder, input, latentState), input, decoder, output);
    return Dist.score(output);
};

// nn_decodeSample
//
// decoder : decoder initialized by nn_initDecoder
// input : observed input (probably passed through encoder to construct state)
// latentState : state to decode
// distributionFn : decoder output, input, decoder -> Distribution
// [maybeObservation] : Observation to factor on
//
// return sample from distribution given maybeObservation
var nn_decodeSample = function(decoder, input, latentState, distributionFn, maybeObservation) {
    var Dist = nn_decodeDistribution(decoder, input, latentState, distributionFn, maybeObservation);
    return util_observeHelper(Dist, maybeObservation);
};

// nn_decodeScoredSamples
//
// decoder : decoder initialized by seq_initDecoder
// input : observed input (probably passed through encoder to construct state)
// latentState : state to decode
// distributionFn : decoder output, input, decoder -> Distribution
// n : number of samples
// [maybeObserved] : Observation to factor on
// [maybeType] : Maybe util.type of items in distribution support for distribution returned by distributionFn
//
// return at most n (value, score) samples possibly including maybeObserved
var nn_decodeScoredSamples = function(decoder, input, latentState, distributionFn, n, maybeObserved, maybeType) {
    var Dist = nn_decodeDistribution(decoder, input, latentState, distributionFn);
    var samples = repeat((maybeObserved !== undefined) ? n - 1 : n, function() { var s = sample(Dist); return { value : s, score : Dist.score(s) }});
    if (maybeObserved !== undefined) {
        var samplesObs = samples.concat({
            value : maybeObserved,
            score : nn_decodeLL(decoder, maybeObserved, input, latentState, distributionFn)
        });

        return gameppl.util.removeDuplicateScoredValues(samplesObs, maybeType);
    } else {
        return gameppl.util.removeDuplicateScoredValues(samples, maybeType);
    }
};

// nn_initSequenceEncoderStep
//
// constructs a sequence encoder step function for use in sequence models (seq.wppl)
//
// params:
//   name : Reference name
//   inputType : DATA_TYPE_VECTOR or DATA_TYPE_SCALAR (defaults to DATA_TYPE_SCALAR)
//   latentDimension : Dimension of hidden state (must be even)
//   inputDimension : Dimension of the input
//
// return a sequence encoder step function that takes a state and an input, and outputs a next
// state.
var nn_initSequenceEncoderStep = function(params) {
    assert.ok(params.latentDimension % 2 === 0, 'Dimension for sequence model expected to be even');
    var stepType = params.maybeStepType || NN_SEQUENCE_STEP_LSTM; // Unused for now
    var enc_net = lstm('seq_enc_h_0_' + params.name, { hdim : params.latentDimension, xdim : params.inputDimension, param : modelParam });
    return function(prevState, x) {
        assert.ok(dims(prevState)[0] === params.latentDimension, 'Previous hidden vector has unexpected dimension');
        var x_v = (params.inputType === DATA_TYPE_VECTOR) ? x : oneHot(x, params.inputDimension);
        var nextState = enc_net(prevState, x_v);
        return nextState;
    };
};

// nn_initSequenceDecoderStep
//
// constructs a sequence decoder step function for use in sequence models (seq.wppl)
//
// params:
//   name : Reference name
//   latentDimension : Dimension of hidden state (must be even)
//   outputDimension : Dimension of output
//
// return a sequence decoder step function that takes a state and a sequence of previous
// inputs, and outputs an object (state, outputs) where state is a latent state, and outputs
// is a (value, score) list of scored next values for the decoded sequence
var nn_initSequenceDecoderStep = function(params) {
    assert.ok(params.latentDimension % 2 === 0, 'Dimension for sequence model expected to be even');
    var stepType = params.maybeStepType || NN_SEQUENCE_STEP_LSTM; // Unused for now
    var dec_net_h = lstm('seq_dec_layer_0_' + params.name, { hdim : params.latentDimension, xdim : params.outputDimension, param : modelParam });
    var dec_net_out = stack([softmax, affine('seq_dec_out' + params.name, { in : params.latentDimension + params.outputDimension, out : params.outputDimension, param : modelParam }), concat]);
    return function(state, xs_prev) {
        assert.ok(dims(state)[0] === params.latentDimension, 'Previous hidden vector has unexpected dimension');
        var v = oneHot(xs_prev[xs_prev.length - 1], params.outputDimension);
        var nextState = dec_net_h(state, v);
        var ps = dec_net_out([nextState, v]);
        var pOut = T.toScalars(ps);
        //display(pOut);
        //display(ps);
        var outputs = mapIndexed(function(value, score) { return { value : value, score : score } }, pOut);
        return { outputs : outputs, state: nextState }
    };
};
