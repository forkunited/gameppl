var DECODER_SIGMOID = 0;
var DECODER_LINEAR = 1;
var DECODER_SOFTMAX = 2;

var SEQUENCE_DECODER_LAZY_LSTM_CATEGORICAL = 0;
var SEQUENCE_DECODER_GREEDY_BEAM_CATEGORICAL = 1;

var makeModelParam = param; // modelParamL2(10);

var makeEncoder = function(params) {
    return stack([
        tanh,
        bias('bias1', makeModelParam),
        affine(params.latentDimension*2, 'layer1', makeModelParam)
    ]);
}

// Sequence encoder repeats encoder step until input is completely digested
// params : { latentDimension }
var makeSequenceEncoder = function(params) {
    var makeEncoderStep = function() {
        var enc_net = lstm(params.latentDimension*2, 'enc-h', makeModelParam);     // <- THIS LINE CHANGED
        return function(prevState, x) {
            assert.ok(dims(prevState)[0] === params.latentDimension*2, 'Previous hidden vector has unexpected dimension');
            var nextState = enc_net(prevState, x);    // Originally, oneHot was done here
            return nextState;
        };
    };

    var initialState = makeModelParam({ name: 'enc-init', dims: [params.latentDimension*2, 1] });
    var encoderStep = makeEncoderStep();
    var encoder = function(xs, maybeState) {
        var state = maybeState || initialState;
        if (xs.length === 0) {
            return state;
        } else {
            var nextState = encoderStep(state, xs[0]);
            return encoder(xs.slice(1), nextState);
        }
    };
    return encoder;
};

var makeDecoder = function(params) {
    if (params.decoderType == DECODER_SIGMOID) {
        return stack([
            sigmoid,
            affine(params.outputDimension, 'dec0', makeModelParam)
        ]);
    } else if (params.decoderType == DECODER_LINEAR) {
        return stack([
            affine(params.outputDimension, 'dec0', makeModelParam)
        ]);
    } else {
        return stack([
            softmax,
            affine(params.outputDimension, 'dec0', makeModelParam)
        ]);
    }
};

// Decoder repeats decoder step until terminal symbol is observed or max length is exceeded
// params: { outputDimension, latentDimension, outputStartSymbolIndex, outputTerminalSymbolIndex }
// returns decoder
//     Decoder
//         opts { state, remainingSeq (sequence of vocabulary indices) }
var makeSequenceDecoder_LLC = function(params) {
    var observeHelper = function(dist, val) {
        if (val !== undefined) {
            factor(dist.score(val));
            return val;
        } else {
            return sample(dist, {
                guide: function() {
                    return dist; // prevent auto-guide in Forward; always use model dist
                }
            });
        }
    };

    var makeDecoderStep = function() {
        var dec_net_h = lstm(params.latentDimension*2, 'dec-h', makeModelParam);
        var dec_net_out = stack([softmax, affine(params.outputDimension, 'dec-out', makeModelParam), concat]);
        return function(x_prev, state) {
            assert.ok(dims(state)[0] === params.latentDimension*2, 'Previous hidden vector has unexpected dimension');
            var k = x_prev;
            var v = oneHot(k, params.outputDimension);
            var nextState = dec_net_h(state, v);
            var ps = dec_net_out([nextState, v]);
            return { ps : ps, state: nextState }
        };
    };

    var vocabulary = _.range(params.outputDimension);
    var decoderStep = makeDecoderStep();
    var decoder = function(opts) {
        var state = opts.state;
        var n = opts.n || 0;
        var generatedSeq = opts.generatedSeq || [params.outputStartSymbolIndex];
        var remainingSeq = opts.remainingSeq;
        var x_prev = _.last(generatedSeq);
        if ((n === (params.maxSeqLength + 2)) || (x_prev === params.outputTerminalSymbolIndex)) {
            // We're not slicing off the terminal symbol since not all strings self-terminate,
            // and we might like to know which do
            return generatedSeq.slice(1);
        } else {
            var tmp = decoderStep(x_prev, state);
            var nextState = tmp.state;
            var ps = tmp.ps;

            // NOTE: The observations (output sequences) are currently assumed to be sequences of
            // singleton tensors.  This is why we messily index into data[0] below.
            //
            // The motivation for this messiness is that the current implementation
            // assumes for simplicity that outputs
            // are always tensors.  This will make it easy in the
            // future if we want to have a decorder
            // that decodes sequences of vectors (e.g. word2vec vectors) rather than sequences
            // of single index values.
            var observedX = remainingSeq ? remainingSeq[0].data[0] : undefined;

            var generatedX = observeHelper(Categorical({ ps : ps, vs: vocabulary }), observedX);
            return decoder({
                state: nextState,
                n: n+1,
                generatedSeq: generatedSeq.concat([ generatedX ]),
                remainingSeq: remainingSeq ? remainingSeq.slice(1) : undefined
            });
        }
    };
    return decoder;
};

var makeSequenceDecoder_GBC = function(params) {
    var f = params.decoderStepFn; // (state x input) -> (next state, (value, score, heuristic, fixed, terminal) list)
    var B = params.B; // Beam size

    var Decoder = function(states, seqs, scores, k) {
        var nextScores = _.flatten(mapIndexed(
            function(index, state) {
                var seq = seqs[index];
                var score = scores[index];
                var nextStateAndOutputs = f(state, seq);
                var nextState = nextStateAndOutputs.state;

                return map(function(output) {
                    var nextOutput = output.value;
                    var nextScore = output.score + score;
                    var nextHeuristicScore = output.heuristic + output.score + score;
                    var fixed = output.fixed;
                    var terminal = output.terminal;

                    return { index : index,
                             nextState : nextState,
                             nextOutput : nextOutput,
                             nextScore : nextScore,
                             nextHeuristicScore : nextHeuristicScore,
                             fixed : fixed,
                             terminal : terminal
                    };
                }, nextStateAndOutputs.outputs);
        }, states));

        var sortedNextScores = sort(nextScores, gt, function(obj) { (obj.fixed) ? Infinity : obj.nextHeuristicScore });
        var nextBeam = _.first(sortedNextScores, B);

        // Make next states, seqs, scores
        // Check all terminated
        var nextStates = map(function(o) { o.nextState }, nextBeam);
        var nextSeqs = map(function(o) { seqs[o.index].concat(o.nextOutput) }, nextBeam);
        var nextScores = map(function(o) { o.nextScore }, nextBeam);
        var allTerminal = all(function(o) { o.terminal }, nextBeam);

        if (k === 0 || allTerminal) {
            return Categorical({ vs : nextSeqs , ps : nextScores});
        } else {
            return Decoder(nextStates, nextSeqs, nextScores, k-1);
        }
    };

    return Decoder;
};

var makeSequenceInputModel = function(params) {
    var encoder = makeSequenceEncoder(params);
    var decoder = makeDecoder(params);

    return function(datum) {
        var state = encoder(datum);
        return decoder(state);
    }
}

var makeSequenceOutputModel = function(params) {
    var encoder = makeEncoder(params);

    if (params.decoderType === SEQUENCE_DECODER_LAZY_LSTM_CATEGORICAL) {
        // NOTE: This model observes in training
        var decoder = makeSequenceDecoder_LLC(params);
        return function (datum, observation) {
            var state = encoder(datum);
            return decoder({state: state, remainingSeq: observation});
        }
    } else if (params.decoderType === SEQUENCE_DECODER_GREEDY_BEAM_CATEGORICAL) {
        var decoder = makeSequenceDecorder_GBC(params);
        return function (datum) {
            var state = encoder(datum);
            return decoder(state);
        }
    }
}